## Link面试刷题平台

### 1、基于Redis BitMap + Redisson 实现用户年度刷题记录的统计，和使用数据库用户相比存储节约几百倍空间。在此基础上通过本地缓存 + 返回值优化 + 位运算进一步提升接口性能。

#### 是否用到了分布式锁，为什么想到用Redisson（易点云-北京）

这个项目是一个单机项目，并没有用到分布式锁。

之所以使用Redisson，是因为Redisson中实现位图的方式是RBitSet，RBitSet和Java的BitSet的基础API都一样，使用所以使用RBitSet比使用Redis的BitMap更容易。

另外如果以后项目需要被改造为一个分布式项目，需要使用分布式锁，可以直接使用原来的Redisson，能少修改一些代码。

#### 你是怎么实现数据持久化的，怎么实现Redis数据丢失问题。（易点云-北京）

因为Redis默认有两种数据持久化方式，RDB和AOF，所以数据并不会丢失。

#### 如果不使用BitMap，使用MySQL你会怎么设计数据库，使用数据库设计内存也没有大多少，为什么要用位图呢（易点云-北京）



### 2、搭建 ES 代替 MySQL 模糊查询，并通过为索引绑定 ik 分词器实现灵活的分词搜索。

#### 说一下怎么把数据库同步到ES，增量同步除了定时任务还有哪些方式（易点云-北京）

第一次把ES应用到该项目的时候，我是把数据库的内容全量同步到了ES。

之后我写了一个定时任务，每隔一分钟查询数据库五分钟内的数据。把最新的数据同步到ES。

由于每隔一分钟查询数据库五分钟内的数据，为系统提供了一定的容错能力，即使哪一次没有把数据同步进来，后续仍有可能把数据同步进来。同时和每次都查全部数据库相比，很大程度减轻了数据库的压力。

除了定时任务，还有以下方式实现定时任务同步：

1. 双写：向数据库写入数据的时候，也要向ES写入数据。
   - 这种方式的优点在于，可以实时更新ES
   - 缺点在于ES 通常没有像数据库那样成熟的事务回滚机制，可能会导致数据不一致，需要设计一些补偿机制来解决这个问题，如如通过定时任务、日志和告警修复ES不同步的数据
   - 这种方式还有影响系统性能的缺点，因为每次写入数据库都要同步写入ES，增加了写入的延迟，只适合小规模的数据同步场景。
   - 可以通过设计一个消息队列，让消息队列异步写入ES，同时利用消息队列的重试机制，解决上面提到的两个问题。

2. Logstash数据同步管道 和 监听MySQL binlog
   - Logstash方式一般需要配合kafka消息队列和beats采集器，适合大规模分布式的应用场景
   - 监听MySQL binlog方式的原理是 数据库每次修改时，会修改 binlog 文件，只要监听该文件的修改，就能第一时间得到消息并处理。可以通过现成的第三方中间件实现这种方式，如阿里巴巴的Canal，Canal解析完binlog信息之后，可以将信息发送给消息队列进行处理
     - 由于我还没有学习kafka，logstash，beats，Canal也没有具体了解过，所以对这两种方式的细节不是很清楚。但是这些技术以后肯定要学，因为ELK stack里除了kabana、ElasticSearch之外，还包含logstash、beats。

#### 数据库同步到ES的具体流程（没问、要看）

1. 设计和新建索引：

   首先设计和新建了ES的索引。新建索引时，在ES中添加了要同步的数据库表的字段，把 题目标题、题目内容、题目答案 这些需要全文搜索的内容 设置为了text类型，并指定他们的分词器为ik分词器，

   另外将 题目标签 这种不需要分词，需要精确匹配的字段设置为了keyword类型，这样就支持用户按照题目标签查找题目。

   另外还把数据库中的userId定义为long类型，editTime、createTime、updateTime定义为了date类型。其中date类型的字段指定了format参数，避免因日期格式不同导致解析错误。

   创建索引时为索引指定了别名，这样能够简化查询，还能在使用新索引时，只需要将别名切换到新的索引，而代码中使用的索引别名不需要该变。

2. 引入ES客户端

   引入Spring Data Elasticsearch作为ES客户端

   使用ElasticsearchRestTemplate进行查询操作

   之后创建了一个EsDTO 和EsDAO，EsDTO用于和索引结构对应，EsDAO继承了ElasticsearchRepository接口，用于和和Elasticsearch 进行交互，执行删除、查询等CRUD操作

3. 向ES全量写入数据

   首先从数据库全量获取题目

   再将获取到的题目类转换为ES实体类

   最后再将ES实体类分批插入到ES中，每批插入500个

   

4. 数据同步--向ES增量写入数据

   最后使用定时任务进行ES数据同步，每分钟从数据库读取五分钟内新增的数据，

   使用ElasticsearchRepository的`saveAll()`方法将最新数据同步到ES中。

   

#### 用户从ES查询的过程（没问、要看）

首先用户能够选择查询条件，比如按照标签查询、按照题目标题题目内容查询。

在我自定义的方法中，首先从用户的查询条件中获取查询参数，比如题目标签、题目内容题目标题等

然后使用`BoolQueryBuilder.filter()` 、 `QueryBuilders.termQuery()`，`BoolQueryBuilder.should()` 、 `QueryBuilders.matchQuery()`、`NativeSearchQueryBuilder()`构造查询条件，

最后调用ElasticsearchRestTemplate的search方法得到查询结果



### 3、基于MyBatis的batch操作实现题目批量管理，通过任务拆分+CompletableFuture并发编程提升批处理性能。

#### 说一下整个流程，包括怎么batch操作，怎么任务拆分，怎么使用CompletableFuture并发编程（易点云-北京）

>  批量操作功能：
>
> - 批量添加题目到题库、批量移除题目从题库中
> - 批量删除题目

首先获取要添加到题库的题目列表。

然后自定义一个线程池，核心线程数20，最大线程数50.

接着定义了一个泛型为CompletableFuture的异步任务列表，用于存放异步任务。

接着又定义了一个大小为1000的batchSize，然后开启一个for循环，循环次数为 列表大小 / batchSize。

每次循环都从题目列表截取一个大小为1000的子列表，然后调用CompletableFuture的`runAsync`方法开启一个异步任务，，在异步任务中执行MyBatisPlus的`saveBatch`方法，将子列表存到数据库中。开启异步任务之后再将该任务添加到异步任务列表里。

在for循环结束之后，调用`CompletableFutere.allOf().join()`方法，等待所有异步任务完成。

所有任务执行完成后，执行自定义的线程池的`shutDown`方法关闭线程池。

### 4、用 Caffeine 本地缓存提升题库查询性能，并通过接入 Hotkey 并配置热 key 探测规则来自动缓存热门题目，防止瞬时流量击垮数据库。

#### 说一下整个流程（没问，要看）

这里是引入了一个中间件，叫JDHotKey；

在HotKeyConfig配置类中配置了Caffeine缓存的数量；

安装并启动etcd（etcd是一个开源的分布式键值存储库）；

安装HotKeyWorker并使Worker连接上etcd；、

之后启动hotkey的控制台，在控制台内配置热点探测规则。判断 `bank_detail_` 开头的 key，如果 5 秒访问 10 次，就会被推送到 jvm 内存中，将这个热 key 缓存 10 分钟。

在配置完后我又在自己的项目中引入了hotkey-client依赖，编写了初始化hotkey-client的配置类，配置类中配置了etcd服务的地址，本地caffeine缓存最大数量，热key的推送间隔时间。

最后将hotkey整合到了我的业务中，在调用获取题库接口时，会判断当前要获取的题库是不是热key，如果是热key，就直接从缓存中获取；如果不是热key，则从数据库中获取该题库并判断该题库满不满足成为热key的条件，如果满足则将结果设置为热key，并返回结果，下次调用再请求该题库时，就会直接返回缓存中的结果。

以上就是使用Caffeine和HotKey的流程，整体参考了该HotKey开源项目的的使用文档；

### 5、基于 Sentinel 注解 + Dashboard 对获取题库列表接口进行限流，并通过 fallbackHandler 配置熔断。

#### 说一下整个流程（没问，要看）

首先下载并启动了 sentinel-dashboard

之后在项目中引入spring-cloud-starter-alibaba-sentinel依赖

接下来定义资源和规则：

- 使用注解定义资源

  通过在“分页查看题库接口”上添加`@SentinelResource`注解，将该接口定义为资源，在注解中还通过`value` 指定资源名称，并将`blockHandler` 处理规则拦截异常 指定为 我的自定义异常方法`handleBlockException`，`fallback` 处理业务方法执行异常 指定为 我的自定义`handleFallBack`方法

  接着实现了handleFallBack方法和handleBlockException方法。

  handleFallBack方法定义了降级的操作，具体实现是当调用该方法时，直接返回空数据作为降级服务。

  具体实现是判断传入的 `BlockException`参数，如果该参数是 `DegradeException`的实例，就执行降级操作，调用`handleFallBack()`方法，否则返回异常，提示用户系统压力过大。

- 基于控制台定义规则

  我在控制台配置了限流规则和熔断规则

  限流规则是如果某个IP在一分钟内查看题目列表的次数超过六十次，就提示“访问过于频繁，请稍后再试”

  熔断规则是如果接口异常率超过 10%，或者慢调用（响应时长 > 3 秒）的比例大于 20%，触发 60 秒熔断，出发熔断之后客户端每次请求都会直接返回空数据。

### 6、通过 UserAgent 识别用户设备，并基于 Sa-Token 快速实现同端登录冲突检测。

#### 说一下整个流程，为什么选择Sa-Token（没问，要看）



### 项目中用到了nacos吗，说说nacos的作用（没问要看）



### 请介绍面试刷题平台的完整流程

首先普通用户可以浏览题库，在登陆之后才可以查看具体的题目，在个人中心可以查看年度刷题记录，和个人简介。
管理员用户拥有普通用户的所有权限，除此之外还可以进行用户管理、题库管理和题目管理。

### 请介绍整个面试刷题平台的后端架构设计，主要模块及其作用是什么。

### 你是如何一步步完成面试刷题平台的

我这个项目总体上分为了三步完成。

1. 首先第一阶段，我用SpringBoot、MyBatis、Redis、MySQL这些基本的技术完成后端基本功能，包括用户登录注册、增删改查题目、题库和用户。然后又用React + Next.js完成了基本的前端页面。
   （时间方面补充：第一阶段花了我大概一个星期吧，大部分时间都花在了前端上面。因为在这个项目之前我做过别的项目，这些项目的后端基本功能都很多相似的地方，所以实现起来很快。而前端我的熟练度比较低，花了很多时间，中途还依赖AI很多帮助才完成了前端开发。）
2. 然后在第二阶段，我对第一阶段的基本功能进行了补充。我先列出了想要完善的功能，包括完善分词搜索，实现LeetCode的刷题日历图那样的效果、批量管理题目、和自动缓存热门题目。列出这些功能后，我就开始了具体实现，分词搜索采用了ElasticSearch，批量管理题目使用了Druid连接池和并发编程实现，热门题目使用京东HotKey开源框架，刷题日历功能最开始采用的是MySQL方式实现的，后来仔细思考了一下，感觉MySQL不是最好的解决方式，最后在网上考到BitMap能够实现签到功能的帖子，而我又想到Redis里有一个数据结构是 Redis BitMap，所以最后采用Redis BitMao实现签到功能。
3. 最后一个阶段，我考虑了对项目的安全性进行了优化，引入了Sentinel进行流量控制，引入Nacos实现动态IP黑白名单，引入了Sa-Token同端登陆检测，还实现了基于Redis的分级反爬虫策略。

### 你在该项目的开发过程中遇到的最大挑战是什么，是如何解决的（todo）

可从用户刷题记录日历，Sentinel限流熔断、Sa-Token同端登陆检测（如何检测登陆设备是手机）

### 请介绍整个整个面试刷题平台的架构设计，主要模块和作用是什么

整个项目后端分为一下模块，分别是：

用户模块、题库模块、题目模块、流控管理模块、和配置模块。

**用户模块**提供登陆注册功能、并给管理员提供增删改查用户的功能；
**题库模块**提供浏览题库的功能，另外还提供给管理员添加，删除，修改题库的功能；
**题目模块**提供浏览和搜索题目的功能，另外还提供给管理员添加、删除、修改题目的功能。
用户在登录之后就可以通过题库模块和题目模块浏览题库和题目。
**流量控制模块**通过自动缓存热点题目，提升用户访问效率并减少数据库压力；必要时进行限流和熔断等操作，控制网站流量保护系统。
**配置模块**通过Nacos实时获取最新用户黑白名单配置，用户在访问题目模块时经过黑白名单校验，提升系统安全性。

### 请介绍本项目的数据库设计，可以从字段设计的角度考虑

该项目的数据库分为四个表，分别是用户表、题目表、题库表、题目题库关系表。

- 首先图片字段存储的是url地址，而不是完整的图片，提升了题库的检索性能
- 考虑到题库表中的title字段、题目表中的title和userId作为常见且唯一的搜索条件，所以都添加了索引提升查询性能。
- 使用text类型来存储题目答案，防止字段溢出；
- 在题库题目关系表中，通过给题库id和题目id添加唯一联合索引，防止了一个题目被多次添加到一个题库中。此外我还将题库id放在了左边，这样做是因为大部分查询是基于题库进行查询的，例如代码中有查询某个题库下的所有题目，还有在某个题库下查询题目，将题目id放在左边符合最左匹配原则，查询会更高效

### 什么是BitMap？使用它有什么优点

BitMap就是位图，是一种使用位来表示数据的紧凑数据类型，每个位可存储0或1两个值。常用来表示状态或标志。

使用BitMap的优点有节约内存、查询效率高。
因为每个位仅占用1Bit，在大规模存储二值数据时，节约效果十分明显。
BitMap可以通过与运算查找某个元素是否存在，这种查找十分高效，时间复杂度仅为O(1)

### 你是如何基于BitMap实现用户年度刷题记录统计的？又如何进一步优化接口性能。



## Link在线判题平台

### 1、 设计和实现了多种代码沙箱。通过静态工厂模式+Spring 配置化的方式实现了对多种代码沙箱的灵活调用。

#### 说一下具体的实现（易点云-北京）

首先有一个CodeSandboxFactory -- 代码沙箱工厂类，这个类中实现了一个静态的`newInstance()`方法，该方法传入一个String类型的参数，根据该参数的值判断应该创建哪种代码沙箱对象。

这个参数配置在了项目的配置文件里，需要创建代码沙箱的类通过`@Value`注解读取该配置项并将值赋值给变量，最后将该变量作为参数传递给`newInstance()`方法。

`newInstance()`方法可以创建三种代码沙箱对象，分别是“示例代码沙箱”，“远程代码沙箱”，“第三方代码沙箱”。

- 示例代码沙箱是用来跑通整个项目流程的，里边并没有运行代码和判题的逻辑，无论接收到什么参数，都会返回固定的值。主要在Debug的时候使用。
- 远程代码沙箱
- 第三方代码沙箱用来调用第三方代码沙箱接口，目前还没有实现。

以上就是通过静态工厂模式创建代码沙箱的全部流程。

### 2、使用Docker-Java库创建Docker容器隔离执行代码，并通过 tty 和 Docker 进行传参交互，实现更安全的代码沙箱。编写 Java 脚本自测代码沙箱，模拟了多种程序异常情况并针对性解决，如使用守护线程 + Thread.sleep 等待机制实现了对进程的超时中断

#### 具体说一下模拟了哪些异常情况，怎么写脚本测。说一下这个流程（易点云-北京）

我一共模拟了三种异常情况，也就是写了三段会造成程序异常Java脚本，让代码沙箱分别运行这三段代码。

1. 第一种情况是**用户代码执行时间过长**的情况，我在Java脚本里加入了`Thread.sleep()`方法，让程序睡眠很长时间。假如不处理这种情况，用户上传的代码和我一样加入了`Thread.sleep()`，程序就不会释放资源，最终导致程序卡死。

   我的解决办法是，在运行用户上传的代码之前，启动一个守护线程，该线程会睡眠5s，5s后若用户的代码仍在运行，会调用Process的`destory()`方法，销毁用户执行代码的子进程。

2. 第二种情况是**用户一直向内存中写入数据**的情况，我在Java脚本里加入了一段一直向内存中写入数据的代码。之后我用代码沙箱运行该脚本时，发现子进程报OOM异常。假如不处理这种情况，子进程一直向内存中写入数据，可能会使整个系统资源耗尽，从而影响到主进程。

   我的解决办法是限制用户代码进程的堆内存，在运行用户代码时，加上Java -Xmx256m，这样子进程在OOM之前，不会无限制占用系统资源。

3. 第三种情况是**用户向服务器写入恶意程序**，我在Java脚本中创建了一个bat文件，并向该文件写入一段简单的命令。用户也可以通过这种方式向服务器写入恶意脚本或执行恶意命令，比如删除服务器资源，获取服务器文件内容等。

   我的解决办法每次用户上传一次代码，代码沙箱模块都会基于 openjdk:8 这个镜像 创建一个docker容器，并将用户上传的代码文件挂载到容器的/app目录内，通过在容器内运行脚本将用户和服务器隔离开。


### 3、 使用模板方法模式定义标准代码执行的流程，允许子类自行扩展部分流程，大幅简化冗余代码

#### 说一下这里的模板方法模式（易点云-北京）

我先定义了一个JavaCodeSandboxTemplate抽象类，也就是Java代码沙箱模板。该模板定义并实现了这些流程：

1. 把用户代码保存为文件 -- `saveCodeToFile()`
2. 编译代码，得到class文件 -- `compileFile()`
3. 执行代码，得到输出结果 -- `runFile()`
4. 收集整理输出结果 -- `getOutputResponse()`
5. 文件清理 -- `deleteFile()`

还定义了一个抽象方法 `executeCode()`。

之后创建了两个类继承该抽象类，一个是JavaNativeCodeSandbox、一个是JavaDockerSandbox。这两个类分别用来实现本地直接运行用户上传的Java代码，和创建Docker容器运行用户上传的Java代码。

这两个子类分别重写父类的`executeCode()`方法实现不同的功能。

### 4、选用策略模式代替 if else 独立封装了不同语言的判题算法，提高系统的可维护性。

#### 说一下这里边的策略模式（易点云-北京）

首先定义了一个JudgeContext类，和一个JudgeStrategy接口。然后定义了两个类，一个是DefultJudgeStrategy，一个是JavaJudgeStrategy，这两个类实现了JudgeStrategy接口，用于不同场景的判题策略。

JudgeContext类里边定义了JudgeStrategy类型的字段，并为该字段增加了set方法，可以通过`new JudgeContext()`时传入JudgeStrategy的实现类或者向`set()`方法传入JudgeStrategy的实现类，来指定具体使用哪种判题策略。

JudgeContext还有一个`doJudge()`方法，该方法会调用JudgeStrategy的`doJudge()`方法。

其实DefaultJudgeStrategy类和JavaJudgeStrategy类的功能基本一样，都是用来判断用户提交的Java代码执行结果是否正确。这里使用策略模式是考虑到了以后代码的拓展，假如以后我想增加判断用户提交的C++代码、Python代码的结果的功能，我只需要增加一个CppJudgeStrategy、PythonJudgeStrategy类，并实现对应的`doJudge()`方法就行了。

### 5、使用SpringCloudGateway对各服务接口进行聚合和路由，通过Nacos+OpenFeign实现各模块相互调用。

#### 说一下gateway 、说一下怎么实现相互调用， 说一下配置文件里有哪些参数可以配置路由（易点云-北京）

我把该原本的单机项目拆分成了七个微服务项目

- 首先创建了一个gateway服务，用于聚合所有接口，统一处理前端请求；
- 还创建了一个common服务，将原来单机项目存放的全局的异常处理器、工具类、全局常量等内容放在该项目里；
- 还创建了一个model服务，将原来单机项目的实体类，如DAO、DTO、VO之类的放在该项目里；
- 还创建了一个service-client服务，只存放接口，不存放具体实现，供多个服务之间共享
- 接下来把原项目的用户模块拆分为了user-service服务，负责用户注册、登录和用户管理；
- 把原项目的题目模块拆分为了question-service服务，负责创建、查询、删除、修改题目和在线做题、在线提交；
- 最后把原项目判题模块拆分为了judge-service服务，负责将用户代码传到代码沙箱服务，在得到代码沙箱服务的响应后，根据代码沙箱的相应信息执行判题逻辑，判断题目结果是否正确。

**Gateway方面**：

- 我在gateway服务的配置文件中，为user-service服务、question-service服务、judge-service服务分别定义了一个路由规则。
- 每个路由规则都指定了id、uri、predicates。
- 其中uri使用的是`lb://{微服务在 Nacos 中注册的服务名}`（`lb://` 表示使用 Spring Cloud LoadBalancer 进行负载均衡）
- predicates使用的是`Path`断言，当请求的路径匹配 `/api/user/**`，`/api/question/**`，`/api/judge/**`时，会将请求转发给对应的微服务。

**Nacos方面**：

- 我给所有有启动类的服务的启动类上加上了 `@EnableDiscoveryClient`注解，并在配置文件中配置了nacos 的地址，使这些服务能够被自动注册和发现。

**OpenFeign方面**：

- 我在service-client服务里定义了三个接口，分别是JudgreFeignClient、QuestionFeignClient、UserFeignClient，每个接口上都加了`@FeignClient`注解，并且每个接口里都定义了要调用的远程方法。
- 接着在user-service、question-service、judge-service这三个服务的启动类上加了`@EnableFeignClients`注解。

**总流程如下**：

1. 请求首先到达 Gateway（网关），Gateway 根据请求路径进行路由判断。例如，若请求路径为`/api/judge/**`，则会匹配到`linkoj-backend-judge-service`的路由规则。

2. Gateway 从 Nacos 注册中心获取`linkoj-backend-judge-service`的实例信息，包括服务地址和端口等。

3. Gateway 从Nacos获取到`linkoj-backend-judge-service`这个服务的信息之后，会把浏览器发过来的请求转发给`linkoj-backend-judge-service`这个服务。

4. JudgeService 处理请求：

   - 服务启动：`LinkojBackendJudgeServiceApplication`启动时，会通过`@EnableDiscoveryClient`注解向 Nacos 注册自身服务，通过`@EnableFeignClients`注解开启 Feign 客户端功能，由于`@EnableFeignClients`注解填写了basePackages属性，因此会扫描`com.newfbin.linkojbackendserviceclient`包下的 Feign 客户端接口。

   - 请求处理：当`linkoj-backend-judge-service`接收到请求后，会正常处理请求。

     如果在处理请求的过程中调用了其它服务的方法，会通过OpenFeign发起远程调用。例如我的代码里，judge-service服务里有的地方引用了question-service服务的方法，我就通过 `@Resource`注解将QuestionFeignClient引入到judge-service服务类，再通过QuestionFeignClient调用question-service的方法。

5. 获取结果并返回：`judge-service`服务处理完请求后，将结果返回给 Gateway。Gateway 再将结果返回给浏览器，完成整个请求响应过程。

### 6、系统异步将用户提交题目发送给 RabbitMQ 消息队列，并通过 Direct 交换机转发给判题队列，由判题服务进行消费，异步更新提交状态。

#### 说一下整个流程（没问、要看）

- 首先创建了一个名为code_exchange的Direct类型的交换机和一个名为code_queue的队列，并将该队列绑定到交换机上，绑定的路由键为my_routingKey。
- 当用户提交题目时，question-service服务的Producer类调用  RedisTemplate的 `convertAndSend` 方法，将用户提交的代码发送到交换机，根据routing_key将消息路由到队列。
- judge-service服务的Comsumer类里的方法添加了 `@RabbitListener`注解 ，会一直监听队列，当消息到达时就能获取用户提交的代码，并交给 `JudgeService` 的 `doJudge` 方法进行判题并更新提交状态。

### 本项目完整业务流程	
